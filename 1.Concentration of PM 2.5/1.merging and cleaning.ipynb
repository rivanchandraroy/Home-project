{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import pytz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(location, sensor, type = 'detect'):\n",
    "    \n",
    "    if type == \"detect\":\n",
    "        if \"tdoor\" in sensor:\n",
    "            type = 'Outdoor'\n",
    "        elif \"ndoor\" in sensor:\n",
    "            type = 'Indoor'\n",
    "        else:\n",
    "            warnings.warn(\"type not detected\", UserWarning)\n",
    "\n",
    "    print(f'Merging for {location} : {type}')\n",
    "    print('='*50)\n",
    "            \n",
    "    path = f\"Data/Raw files/{location}/{sensor}\"\n",
    "\n",
    "    # Print the path for debugging\n",
    "    print(f\"Looking for CSV files in: {path}\")\n",
    "\n",
    "    # Use glob to get all the CSV files in the directory\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "\n",
    "    # Initialize an empty list to hold the DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Loop through the list of files and read each file into a DataFrame\n",
    "    print(\"Reading file...\")\n",
    "    for file in tqdm(all_files):\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='ascii')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    # Check if df_list is still empty after the loop\n",
    "    if len(df_list) == 0:\n",
    "        raise ValueError(\"No DataFrames were created. Check if the CSV files are valid and readable.\")\n",
    "\n",
    "    # Concatenate all the DataFrames in the list into a single DataFrame\n",
    "    try:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error concatenating DataFrames: {e}\")\n",
    "\n",
    "    ## Taking cols related to time, meteorological parameters and pm2.5\n",
    "    necessary_cols = ['UTCDateTime', 'current_humidity', 'current_temp_f', 'current_dewpoint_f', 'pressure', 'pm2_5_cf_1', 'pm2_5_atm', 'pm2_5_cf_1_b', 'pm2_5_atm_b']\n",
    "    merged_df = merged_df[necessary_cols].copy()\n",
    "\n",
    "    # # New algorithm\n",
    "    # def calculate_average_with_error_check(value1, value2, threshold=0.10): ## Updated logic\n",
    "    #     avg = (value1 + value2)/2\n",
    "    #     if avg < 5: avg = np.nan\n",
    "    #     if avg > 1000 : avg = np.nan   ## initially taking upper limit of 1000. It was farther readjusted to 500 afterwards\n",
    "    #     if value1 > 100:\n",
    "    #         if value1 == 0 or value2 == 0:\n",
    "    #             error = float('inf')\n",
    "    #         else:\n",
    "    #             error = abs(value1 - value2) / value1\n",
    "    #         if error <= threshold:\n",
    "    #             return avg\n",
    "    #         else:\n",
    "    #             return np.nan\n",
    "    #     else:\n",
    "    #         if np.absolute(value1-value2) <= 10:\n",
    "    #             return avg\n",
    "    #         else:\n",
    "    #             return np.nan\n",
    "        \n",
    "\n",
    "    # merged_df['pm2_5_atm_avg'] = merged_df.apply(\n",
    "    #         lambda row: calculate_average_with_error_check(row['pm2_5_atm'], row['pm2_5_atm_b']), axis=1)\n",
    "\n",
    "\n",
    "    # merged_df['pm2_5_cf_1_avg'] = merged_df.apply(\n",
    "    #         lambda row: calculate_average_with_error_check(row['pm2_5_cf_1'], row['pm2_5_cf_1_b']), axis=1)\n",
    "\n",
    "    try:\n",
    "        merged_df.to_csv(f'Data/Raw files/{location}/{type}_merged.csv', index = False)\n",
    "    except Exception as e:\n",
    "        print(\"Error in saving file...\")\n",
    "        print(e)\n",
    "        while True:\n",
    "            print(\"1. Retry\")\n",
    "            print(\"2. Skip\")\n",
    "            option = int(input())\n",
    "            if option == 1:\n",
    "                try: \n",
    "                    merged_df.to_csv(f'Data/Raw files/{location}/{type}_merged.csv', index = False)\n",
    "                except Exception as e:\n",
    "                    print(\"Error again\", e)\n",
    "                    continue\n",
    "            elif option == 2:\n",
    "                break\n",
    "            else:\n",
    "                print(\"invalid input\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    print(f'file saved : Data/Raw files/{location}/{type}_merged.csv')\n",
    "\n",
    "    # length = merged_df.shape[0]\n",
    "    # atmdata = length - merged_df['pm2_5_atm_avg'].isna().sum()\n",
    "    # cfdata = length - merged_df['pm2_5_cf_1_avg'].isna().sum()\n",
    "\n",
    "    # return atmdata/length*100, cfdata/length*100, length\n",
    "\n",
    "\n",
    "# merge(\"Ajimpur home data\", \"indoor Sensor No 12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'Data/Raw file'\n",
    "locations = [f for f in os.listdir(dir) if os.path.isdir(os.path.join(dir, f))]\n",
    "\n",
    "data = {\n",
    "    'location' : [],\n",
    "    'Indoor' : [],\n",
    "    'Outdoor' : [],\n",
    "    'Indoor length' : [],\n",
    "    'Outdoor length' : []\n",
    "}\n",
    "\n",
    "for location in locations:\n",
    "    sensors = [s for s in os.listdir(os.path.join(dir, location)) if os.path.isdir(os.path.join(dir, location, s))]\n",
    "    data['location'].append(location)\n",
    "\n",
    "    for sensor in sensors:\n",
    "        if \"tdoor\" in sensor:\n",
    "            type = 'Outdoor'\n",
    "        elif \"ndoor\" in sensor:\n",
    "            type = 'Indoor'\n",
    "        else:\n",
    "            warnings.warn(\"type not detected\", UserWarning)\n",
    "\n",
    "        atmp, cfp, length = merge(location, sensor)\n",
    "        print(f'atm : {atmp}')\n",
    "        print(f'cf : {cfp}')\n",
    "        print(f'length : {length}')\n",
    "        print()\n",
    "\n",
    "        if type == \"Indoor\":\n",
    "            data[\"Indoor\"].append(float(atmp))\n",
    "            data['Indoor length'].append(int(length))\n",
    "        if type == \"Outdoor\":\n",
    "            data[\"Outdoor\"].append(float(atmp))\n",
    "            data['Outdoor length'].append(int(length))\n",
    "\n",
    "pd.DataFrame(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(all_in_one)",
   "language": "python",
   "name": "all_in_one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
